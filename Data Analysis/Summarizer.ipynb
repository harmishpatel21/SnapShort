{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarizer.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/harmishpatel21/SnapShort/blob/main/Summarizer.ipynb",
      "authorship_tag": "ABX9TyNrFh9uqJqF+CnhoQYvWH80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3c7c1f6f274480490ce2ae440a92b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8aced8f64334c1d9c74f4747dc33875",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1b936564d5e45f08ba6517416adac6b",
              "IPY_MODEL_fdbfc0647e9e4495b1f8e1ea03f1abd1"
            ]
          }
        },
        "c8aced8f64334c1d9c74f4747dc33875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1b936564d5e45f08ba6517416adac6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_be8a5794d1e64575a0e8f13fd1ddcb4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44f4fcace5544641948361f3063d22ec"
          }
        },
        "fdbfc0647e9e4495b1f8e1ea03f1abd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b52d2f6022354d5ebf74f4d611078dbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_852f73765e804a1b88c8ed10aae2fb4e"
          }
        },
        "be8a5794d1e64575a0e8f13fd1ddcb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44f4fcace5544641948361f3063d22ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b52d2f6022354d5ebf74f4d611078dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "852f73765e804a1b88c8ed10aae2fb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harmishpatel21/SnapShort/blob/main/Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTfILcDIq2eh"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxATmipBrLRL"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB â€“ Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bM8CnKvrLd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c607f5a2-8b25-45a8-f935-a353dbb4c4ac"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 24 18:03:01 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    29W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoyfvXVtrLqU"
      },
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa2rpAdKrL0o"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPWniSzarMKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f625a55a-aadd-40c3-e4fb-018519d41f3a"
      },
      "source": [
        "!git clone https://github.com/harmishpatel21/SnapShort.git"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SnapShort' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMkcED_drMCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "553d4fa3-b889-4e9b-edc0-891b6f87d364"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "# Read Json file\n",
        "data = pd.read_json(\"/content/SnapShort/data000000000000.json\", lines= True)\n",
        "data.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publication_number</th>\n",
              "      <th>abstract</th>\n",
              "      <th>application_number</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US-2006134160-A1</td>\n",
              "      <td>this invention relates to novel calcium phosph...</td>\n",
              "      <td>US-52740605-A</td>\n",
              "      <td>throughout the following description specific ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US-4592498-A</td>\n",
              "      <td>a stapler , particularly for suturing skin wou...</td>\n",
              "      <td>US-71138185-A</td>\n",
              "      <td>preferred embodiments of the invention are ill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US-2014379009-A1</td>\n",
              "      <td>a nerve guidance conduit includes a spiral str...</td>\n",
              "      <td>US-201414313384-A</td>\n",
              "      <td>embodiments of the present invention provide n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US-4157173-A</td>\n",
              "      <td>a rail connector and improvement in seat base ...</td>\n",
              "      <td>US-86596677-A</td>\n",
              "      <td>referring now to the drawings , and particular...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US-2017360443-A1</td>\n",
              "      <td>an anvil assembly is disclosed that includes a...</td>\n",
              "      <td>US-201715606289-A</td>\n",
              "      <td>exemplary embodiments of the presently disclos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  publication_number  ...                                        description\n",
              "0   US-2006134160-A1  ...  throughout the following description specific ...\n",
              "1       US-4592498-A  ...  preferred embodiments of the invention are ill...\n",
              "2   US-2014379009-A1  ...  embodiments of the present invention provide n...\n",
              "3       US-4157173-A  ...  referring now to the drawings , and particular...\n",
              "4   US-2017360443-A1  ...  exemplary embodiments of the presently disclos...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e07qu4c1ttSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "fbdbabf5-b2a6-4650-c550-c8f78ec22617"
      },
      "source": [
        "import re\n",
        "pattern = \"[^\\x00-\\x7F]+\"\n",
        "data['description'] = data['description'].apply(lambda x: re.sub(pattern, '', x))\n",
        "data['abstract'] = data['abstract'].apply(lambda x: re.sub(pattern, '', x))\n",
        "data.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publication_number</th>\n",
              "      <th>abstract</th>\n",
              "      <th>application_number</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US-2006134160-A1</td>\n",
              "      <td>this invention relates to novel calcium phosph...</td>\n",
              "      <td>US-52740605-A</td>\n",
              "      <td>throughout the following description specific ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US-4592498-A</td>\n",
              "      <td>a stapler , particularly for suturing skin wou...</td>\n",
              "      <td>US-71138185-A</td>\n",
              "      <td>preferred embodiments of the invention are ill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US-2014379009-A1</td>\n",
              "      <td>a nerve guidance conduit includes a spiral str...</td>\n",
              "      <td>US-201414313384-A</td>\n",
              "      <td>embodiments of the present invention provide n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US-4157173-A</td>\n",
              "      <td>a rail connector and improvement in seat base ...</td>\n",
              "      <td>US-86596677-A</td>\n",
              "      <td>referring now to the drawings , and particular...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US-2017360443-A1</td>\n",
              "      <td>an anvil assembly is disclosed that includes a...</td>\n",
              "      <td>US-201715606289-A</td>\n",
              "      <td>exemplary embodiments of the presently disclos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  publication_number  ...                                        description\n",
              "0   US-2006134160-A1  ...  throughout the following description specific ...\n",
              "1       US-4592498-A  ...  preferred embodiments of the invention are ill...\n",
              "2   US-2014379009-A1  ...  embodiments of the present invention provide n...\n",
              "3       US-4157173-A  ...  referring now to the drawings , and particular...\n",
              "4   US-2017360443-A1  ...  exemplary embodiments of the presently disclos...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9JhgfWUttid"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.abstract\n",
        "        self.ctext = self.data.description\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4DimdDAtt-Y"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbO-i242tt8J"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWYTDW7itt4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "d3c7c1f6f274480490ce2ae440a92b04",
            "c8aced8f64334c1d9c74f4747dc33875",
            "c1b936564d5e45f08ba6517416adac6b",
            "fdbfc0647e9e4495b1f8e1ea03f1abd1",
            "be8a5794d1e64575a0e8f13fd1ddcb4f",
            "44f4fcace5544641948361f3063d22ec",
            "b52d2f6022354d5ebf74f4d611078dbc",
            "852f73765e804a1b88c8ed10aae2fb4e"
          ]
        },
        "outputId": "9ed1e5f4-d7ab-4ac9-a842-a398d2911348"
      },
      "source": [
        "# def main():\n",
        "# WandB â€“ Initialize a new run\n",
        "wandb.init(project=\"SnapShort\")\n",
        "\n",
        "# WandB â€“ Config is a variable that holds and saves hyperparameters and inputs\n",
        "# Defining some key variables that will be used later on in the training  \n",
        "config = wandb.config          # Initialize config\n",
        "config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "config.TRAIN_EPOCHS = 4        # number of epochs to train (default: 10)\n",
        "config.VAL_EPOCHS = 1 \n",
        "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "config.SEED = 42               # random seed (default: 42)\n",
        "config.MAX_LEN = 512\n",
        "config.SUMMARY_LEN = 150 \n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(config.SEED) # pytorch random seed\n",
        "np.random.seed(config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "\n",
        "# Importing and Pre-Processing the domain data\n",
        "# Selecting the needed columns only. \n",
        "# Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "# df = pd.read_csv('./data/news_summary.csv',encoding='latin-1')\n",
        "# df = df[['text','ctext']]\n",
        "df = data\n",
        "df = data[['abstract','description']]\n",
        "df['abstract'] = 'summarize: ' + df['abstract']\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Creation of Dataset and Dataloader\n",
        "# Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': config.VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "\n",
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "# Log metrics with wandb\n",
        "wandb.watch(model, log=\"all\")\n",
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(config.TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "# Saving the dataframe as predictions.csv\n",
        "print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('/content/SnapShort/result.csv')\n",
        "    print('Output Files generated for review')\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:24vzm7j0) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 212<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3c7c1f6f274480490ce2ae440a92b04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20201124_162236-24vzm7j0/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20201124_162236-24vzm7j0/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">bright-valley-20</strong>: <a href=\"https://wandb.ai/harrypotter/SnapShort/runs/24vzm7j0\" target=\"_blank\">https://wandb.ai/harrypotter/SnapShort/runs/24vzm7j0</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:24vzm7j0). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.11<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">solar-water-21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/harrypotter/SnapShort\" target=\"_blank\">https://wandb.ai/harrypotter/SnapShort</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/harrypotter/SnapShort/runs/31d08nmf\" target=\"_blank\">https://wandb.ai/harrypotter/SnapShort/runs/31d08nmf</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201124_164956-31d08nmf</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                            abstract                                        description\n",
            "0  summarize: this invention relates to novel cal...  throughout the following description specific ...\n",
            "1  summarize: a stapler , particularly for suturi...  preferred embodiments of the invention are ill...\n",
            "2  summarize: a nerve guidance conduit includes a...  embodiments of the present invention provide n...\n",
            "3  summarize: a rail connector and improvement in...  referring now to the drawings , and particular...\n",
            "4  summarize: an anvil assembly is disclosed that...  exemplary embodiments of the presently disclos...\n",
            "FULL Dataset: (1016, 2)\n",
            "TRAIN Dataset: (813, 2)\n",
            "TEST Dataset: (203, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py:1156: FutureWarning: The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  9.205636024475098\n",
            "Epoch: 1, Loss:  2.227531671524048\n",
            "Epoch: 2, Loss:  1.9908605813980103\n",
            "Epoch: 3, Loss:  1.7905666828155518\n",
            "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
            "Completed 0\n",
            "Completed 100\n",
            "Output Files generated for review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yHKWgYvtt0-"
      },
      "source": [
        "checkpoint = {'state_dict': model.state_dict(),'optimizer' :optimizer.state_dict()}\n",
        "torch.save(checkpoint, '/content/model.json')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSA-5pRMXKQX"
      },
      "source": [
        "checkpoint = {'state_dict': model.state_dict(),'optimizer' :optimizer.state_dict()}\n",
        "torch.save(checkpoint, '/content/drive/MyDrive/model.json')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cl4ocJIC0zX"
      },
      "source": [
        "summary = pd.read_csv(\"/content/SnapShort/model2.csv\")\n",
        "summary.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZMx-fUG4KQZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1TSdl7lttyB"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHsAzb-B3_WP"
      },
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "score = rouge.get_scores(summary['Generated Text'][0],summary['Actual Text'][0])\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0uxRtzY3_UR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIuoaZ_m3_SS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ymrPD83_Kh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQVbU57UttwF"
      },
      "source": [
        "# df = data[['abstract','description']]\n",
        "# df['abstract'] = 'summarize: ' + df['abstract']\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1I8j-btttF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eQuSRmyttov"
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCPlxY8khy-i"
      },
      "source": [
        "model = torch.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zLZcf3abRh7"
      },
      "source": [
        "model = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model_epoch4.pkl\"))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxvj2lVLE7OY"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/model.json')\n",
        "model = TFAutoModelWithLMHead.from_pretrained('./local_model_directory/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb_lMxOBE7KM"
      },
      "source": [
        "## Move to CUDA\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnEtb7dqE7Hq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftPFhChTE7FS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ge2b4uE6_1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McVzphCsE69J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TR0yPpE66n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpDrv5k0E64h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bglRVqspE61h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOcKnEFcE6y1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlpbgvb1E6v0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfTXjV2eE6ti"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abTc0IUpE6rR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u74KGU0PE6nZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}